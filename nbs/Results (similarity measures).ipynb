{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172623cc-1b19-421f-806b-134284bbcd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from itertools import chain, combinations\n",
    "\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "import pyperclip\n",
    "import utils\n",
    "import categorization\n",
    "import scoring\n",
    "import adapted_metrics\n",
    "\n",
    "importlib.reload(categorization)\n",
    "importlib.reload(scoring)\n",
    "importlib.reload(adapted_metrics)\n",
    "\n",
    "from utils import *\n",
    "from categorization import *\n",
    "from scoring import get_N_score\n",
    "from adapted_metrics import * \n",
    "\n",
    "current_path = pathlib.Path().resolve().parent\n",
    "print(current_path)\n",
    "\n",
    "json_files_path = current_path / 'similarity_among_tokens_json_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b19818-be85-4e64-8294-93b6ae53a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(current_path / 'nbs' / 'partial_match_data2.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053f3d87-b200-496b-9e57-e07084df1933",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_similarities = df.copy()\n",
    "\n",
    "tau = 0.95\n",
    "tauprime = 0.95\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i, row in df_with_similarities.iterrows():\n",
    "    train_run = row['run']\n",
    "    dataset = row['dataset']\n",
    "    sts_type = row['sts_type']\n",
    "\n",
    "    arg_orig = str(row['gold_argument']).split()\n",
    "    arg_pred = str(row['predicted_argument']).split()\n",
    "    arg_pred_ids = str(row['pID'])\n",
    "\n",
    "    number_tokens_pred = get_number_of_tokens(arg_pred)\n",
    "    number_tokens_gold = get_number_of_tokens(arg_orig)\n",
    "\n",
    "    with open(json_files_path / f'comparison{i+1}-{dataset}-{sts_type}-{train_run}.json', 'r') as f:\n",
    "        comparison_dict = json.load(f)\n",
    "\n",
    "\n",
    "    similarity_tokens = get_similarity_tokens(arg_pred, arg_orig, tauprime, tau, comparison_dict)\n",
    "\n",
    "    number_similarity_tokens = len(similarity_tokens)\n",
    "\n",
    "    df_with_similarities.at[i, 'adapted_jaccard'] = adapted_jaccard(number_tokens_pred, number_tokens_gold, number_similarity_tokens)\n",
    "\n",
    "    df_with_similarities.at[i, 'adapted_dice'] = adapted_dice(number_tokens_pred, number_tokens_gold, number_similarity_tokens)\n",
    "\n",
    "    df_with_similarities.at[i, 'adapted_sorensen'] = adapted_sorensen(number_tokens_pred, number_tokens_gold, number_similarity_tokens)\n",
    "\n",
    "    df_with_similarities.at[i, 'adapted_symmetric_anderberg'] = adapted_symmetric_anderberg(number_tokens_pred, number_tokens_gold, number_similarity_tokens)\n",
    "\n",
    "    df_with_similarities.at[i, 'adapted_sokal_sneath2'] = adapted_sokal_sneath2(number_tokens_pred, number_tokens_gold, number_similarity_tokens)\n",
    "\n",
    "    df_with_similarities.at[i, 'adapted_ochiai'] = adapted_ochiai(number_tokens_pred, number_tokens_gold, number_similarity_tokens)\n",
    "\n",
    "    df_with_similarities.at[i, 'adapted_kulczynski2'] = adapted_kulczynski2(number_tokens_pred, number_tokens_gold, number_similarity_tokens)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    if (i+1) % 10000 == 0:\n",
    "        print(f\"{i+1} completed [{round(elapsed_time)}]\")\n",
    "\n",
    "df_with_similarities.to_csv(current_path / 'nbs' / f'partial_match_data_with_similarities-{tau}-{tauprime}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59a20b8-c4a7-4a44-8638-290df5ae39ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120474a0-9107-4b77-afbd-2629118ddf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_with_similarities.to_csv(current_path / 'nbs' / 'partial_match_data_with_similarities-09-09-check.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73684b5-7c5f-4d03-8295-97ce38ff0062",
   "metadata": {},
   "source": [
    "# Results\n",
    "<!--  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddd4453-39bc-4663-9524-d06257618167",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 0.8\n",
    "tauprime = 0.8\n",
    "\n",
    "df = pd.read_csv(current_path / 'nbs' / f'partial_match_data_with_similarities-{tau}-{tauprime}.csv')\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762e5385-42c1-4d15-9ea9-028fcf185ac2",
   "metadata": {},
   "source": [
    "## N Score (using similarity measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9453aefe-9713-4886-b766-dca39e5a5ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partial_match_values_for_similarity_metric(subdf, target_measure_name, nrun):\n",
    "    # target_measure_name = f'adapted_{similarity_measure}'\n",
    "    subdf = subdf[subdf['run'] == nrun]\n",
    "    means = subdf.groupby(\"pID\")[target_measure_name].mean().tolist()\n",
    "\n",
    "    return means\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fe362b-d547-4566-9e4d-750d1369a224",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataname = 'ugen'\n",
    "dataname = 'pe'\n",
    "dataname = 'webis'\n",
    "\n",
    "target_column = 'adapted_jaccard'\n",
    "target_column = 'adapted_dice'\n",
    "target_column = 'adapted_sorensen'\n",
    "target_column = 'adapted_symmetric_anderberg'\n",
    "target_column = 'adapted_sokal_sneath2'\n",
    "target_column = 'adapted_ochiai'\n",
    "target_column = 'adapted_kulczynski2'\n",
    "\n",
    "tanda, sts_type = 'simple', 'no_sts'\n",
    "tanda, sts_type = 'tanda-2', 'sts_sbert'\n",
    "tanda, sts_type = 'tanda-2', 'sts_sbert_ft'\n",
    "tanda, sts_type = 'tanda-2', 'sts_arguebert_ft'\n",
    "\n",
    "best_f1 = 0\n",
    "best_model = 0\n",
    "\n",
    "lambda_PM = 1\n",
    "lambda_MU = 1\n",
    "lambda_UNR = 1\n",
    "\n",
    "N_scores = []\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    dirpath = str(current_path / f'results-{tanda}' / f'{dataname}_{sts_type}' / f'test_{dataname}_{i}.txt')\n",
    "    tokens, labels, predictions = parse_file(dirpath)\n",
    "    run_f1 = f1_score(labels, predictions, average='macro')\n",
    "    if (run_f1 > best_f1):\n",
    "        best_model = i\n",
    "        best_f1 = run_f1\n",
    "    \n",
    "    instances = parse_file_for_arg_level(dirpath)\n",
    "    id_values_pairs = get_values_for_predicted_arguments(instances)\n",
    "\n",
    "    number_match, number_partial_match, number_made_ups = get_number_predicted_arguments_per_category(id_values_pairs)\n",
    "    number_unrecognized = get_unrecognized_arguments(instances)\n",
    "        \n",
    "    number_golds = get_gold_arguments(instances)\n",
    "    number_preds = get_pred_arguments(instances)\n",
    "        \n",
    "    assert (number_match + number_partial_match + number_made_ups) == number_preds\n",
    "\n",
    "    subdf = df[(df['dataset'] == dataname) & (df['sts_type'] == sts_type)]\n",
    "    \n",
    "    similarity_values_for_no_match = get_partial_match_values_for_similarity_metric(subdf, target_column, i)\n",
    "\n",
    "\n",
    "    N_score = get_N_score(number_match, number_partial_match, number_made_ups, number_unrecognized, similarity_values_for_no_match, \n",
    "                          number_golds, number_preds, \n",
    "                          lambda_PM, lambda_MU, lambda_UNR)\n",
    "\n",
    "    print(N_score)\n",
    "\n",
    "    N_scores.append(N_score)\n",
    "\n",
    "print(best_model)\n",
    "\n",
    "\n",
    "print(\"BEST score: \", round(N_scores[best_model], 3))\n",
    "\n",
    "print(\"AVG score: \", round(np.mean(N_scores), 3))\n",
    "\n",
    "slist_as_string = f\"{round(N_scores[best_model], 3)} ({round(np.mean(N_scores), 3)}) & \"\n",
    "pyperclip.copy(slist_as_string)\n",
    "\n",
    "print(slist_as_string)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
